{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (50000, 32, 32, 3)\n",
      "Shape of y_train: (50000, 10)\n",
      "Shape of X_test: (10000, 32, 32, 3)\n",
      "Shape of y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print(\"Shape of X_test: {}\".format(X_test.shape))\n",
    "print(\"Shape of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 25,578\n",
      "Trainable params: 25,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "i = keras.Input(shape=(32, 32, 3,))\n",
    "x = layers.Conv2D(16, 3,padding='same',activation=\"relu\")(i)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Conv2D(32, 3,padding='same',activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(10,activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=i, outputs=x, name=\"mnist_model\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_on_batch(X, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        yh = model(X, training=True)\n",
    "        loss_value = loss(y, yh)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "@tf.function\n",
    "def validate_on_batch(X, y):\n",
    "    yh = model(X, training=False)\n",
    "    loss_value = loss(y, yh)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "batch_size = 1024\n",
    "epochs = 10\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=len(X_train)).batch(batch_size)\n",
    "test_data = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(buffer_size=len(X_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] Batch: 48.......... Validation Loss: 1.5902557\n",
      "Epoch [2/10] Batch: 48.......... Validation Loss: 1.4908419\n",
      "Epoch [3/10] Batch: 48.......... Validation Loss: 1.429952\n",
      "Epoch [4/10] Batch: 48.......... Validation Loss: 1.3814714\n",
      "Epoch [5/10] Batch: 48.......... Validation Loss: 1.3311608\n",
      "Epoch [6/10] Batch: 48.......... Validation Loss: 1.299958\n",
      "Epoch [7/10] Batch: 48.......... Validation Loss: 1.268738\n",
      "Epoch [8/10] Batch: 48.......... Validation Loss: 1.2375911\n",
      "Epoch [9/10] Batch: 48.......... Validation Loss: 1.230054\n",
      "Epoch [10/10] Batch: 48.......... Validation Loss: 1.2007405\n"
     ]
    }
   ],
   "source": [
    "best_loss = 99999\n",
    "for epoch in range(0, epochs):\n",
    "    for batch, (X, y) in enumerate(train_data):\n",
    "        train_on_batch(X, y)\n",
    "        print('\\rEpoch [%d/%d] Batch: %d%s' % (epoch + 1, epochs, batch, '.' * (batch % 10)), end='')\n",
    "\n",
    "    val_loss = np.mean([np.mean(validate_on_batch(X, y)) for (X, y) in test_data])\n",
    "    print('. Validation Loss: ' + str(val_loss))\n",
    "    if val_loss < best_loss:\n",
    "        model.save_weights('model.h5')\n",
    "        best_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
